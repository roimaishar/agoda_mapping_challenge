{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agoda mapping challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caiqqieYv9_Y",
        "colab_type": "text"
      },
      "source": [
        "# **Agoda Mapping Challenge**\n",
        "The following code cell is used only when working within Google's Colab workspace:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HqZIIF1vw_4",
        "colab_type": "code",
        "outputId": "f6f3818f-5704-4831-caac-e131af5fbbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXbsQyCTkM3-",
        "colab_type": "code",
        "outputId": "e8b00bd0-bdad-4517-fc5a-1348818bf229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install recordlinkage"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting recordlinkage\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/26/babbca39d74824e8bc17428a8eb04951a1d63318af7d02beeb2106a1ec26/recordlinkage-0.14-py3-none-any.whl (944kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from recordlinkage) (0.22.1)\n",
            "Collecting jellyfish>=0.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/80/bcacc7affb47be7279d7d35225e1a932416ed051b315a7f9df20acf04cbe/jellyfish-0.7.2.tar.gz (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from recordlinkage) (1.17.5)\n",
            "Requirement already satisfied: scipy>=1 in /usr/local/lib/python3.6/dist-packages (from recordlinkage) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from recordlinkage) (0.25.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from recordlinkage) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->recordlinkage) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->recordlinkage) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23->recordlinkage) (1.12.0)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.7.2-cp36-cp36m-linux_x86_64.whl size=72984 sha256=8dc57fba282b81c0d5b4729f62db7759ba2b67b8b0bf99663def596d05a7ad3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/fe/99/d8fa8f2ef7b82a625b0b77a84d319b0b50693659823c4effb4\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: jellyfish, recordlinkage\n",
            "Successfully installed jellyfish-0.7.2 recordlinkage-0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPYs8DnfwJ81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import recordlinkage\n",
        "from recordlinkage.preprocessing import clean\n",
        "from recordlinkage.base import BaseClassifier\n",
        "from recordlinkage.adapters import SKLearnAdapter\n",
        "\n",
        "import sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import ensemble, metrics, model_selection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyVpAkZSwMo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = '/content/drive/My Drive/Work/Job Assignments/Agoda/mappinghotelsdataset.xlsx'\n",
        "df_p1 = pd.read_excel(filepath, sheet_name='Partner1')\n",
        "df_p2 = pd.read_excel(filepath, sheet_name='Partner2')\n",
        "df_examples = pd.read_excel(filepath, sheet_name='examples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC6XDxYGc5r0",
        "colab_type": "text"
      },
      "source": [
        "# Basic EDA and a pair-matching baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vwEFLB_wwus",
        "colab_type": "code",
        "outputId": "a1d41609-336b-4138-d159-ec247ccd3b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "display(df_p1.head(6))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p1.key</th>\n",
              "      <th>p1.hotel_name</th>\n",
              "      <th>p1.city_name</th>\n",
              "      <th>p1.country_code</th>\n",
              "      <th>p1.hotel_address</th>\n",
              "      <th>p1.star_rating</th>\n",
              "      <th>p1.postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5E876BFEA81A39E42E3019FE17303D52</td>\n",
              "      <td>Elite Grande Hotel</td>\n",
              "      <td>Manama</td>\n",
              "      <td>BH</td>\n",
              "      <td>Bldg 3378, Road 2845, Area 428</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4F315989358CC0F3F7869F569887743D</td>\n",
              "      <td>Quality Inn West Chester</td>\n",
              "      <td>West Chester (OH)</td>\n",
              "      <td>US</td>\n",
              "      <td>8567 Cincinnati Dayton Road</td>\n",
              "      <td>3.0</td>\n",
              "      <td>45069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A4EEBCBB9932DADE591248DFFFBDC068</td>\n",
              "      <td>MAP5 Village Resort</td>\n",
              "      <td>Goa</td>\n",
              "      <td>IN</td>\n",
              "      <td>Vithaldas Wadoo</td>\n",
              "      <td>3.0</td>\n",
              "      <td>403512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2833BE9FD49A063A36D3DE1E5E28ABC4</td>\n",
              "      <td>Hampton Inn &amp; Suites San Jose Hotel</td>\n",
              "      <td>San Jose (CA)</td>\n",
              "      <td>US</td>\n",
              "      <td>55 Old Tully Road</td>\n",
              "      <td>3.0</td>\n",
              "      <td>95111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F7C20B50AE5C6C807BAABB65B8926F07</td>\n",
              "      <td>Favehotel Daeng Tompo</td>\n",
              "      <td>Makassar</td>\n",
              "      <td>ID</td>\n",
              "      <td>Daeng Tompo Street number 28, Losari</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>C517E32BB18C1E2ED859947B25629103</td>\n",
              "      <td>Art Cottage Hotel</td>\n",
              "      <td>Ipoh</td>\n",
              "      <td>MY</td>\n",
              "      <td>15 &amp; 17,Jalan Medan Ipoh 1B/1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             p1.key  ... p1.postal_code\n",
              "0  5E876BFEA81A39E42E3019FE17303D52  ...           5458\n",
              "1  4F315989358CC0F3F7869F569887743D  ...          45069\n",
              "2  A4EEBCBB9932DADE591248DFFFBDC068  ...         403512\n",
              "3  2833BE9FD49A063A36D3DE1E5E28ABC4  ...          95111\n",
              "4  F7C20B50AE5C6C807BAABB65B8926F07  ...            NaN\n",
              "5  C517E32BB18C1E2ED859947B25629103  ...          31400\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wck9qYY-di3M",
        "colab_type": "text"
      },
      "source": [
        "**Assumptions:**\n",
        "\n",
        "\n",
        "*   Since \"Matches can only be made within\n",
        "the same country (hotels with different country codes cannot be\n",
        "matched with each other)\", we'll assume country codes are noiseless. Otherwise, the following methods should be revisited. These will be used as our blocking, restricting comparisons only between them.\n",
        "*   The rest of the columns have noise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxov79GS2zV7",
        "colab_type": "code",
        "outputId": "54bf2de7-1a9e-425a-8407-5fb77a8a7dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('number of sample points:', df_p1.shape[0])\n",
        "print('number of sample points [in Examples]:', df_examples.shape[0])\n",
        "\n",
        "# maximal length of entries per country:\n",
        "print('maximal occurnces per country:',\n",
        "      df_p1['p1.country_code'].value_counts().idxmax(), 'with',\n",
        "      df_p1['p1.country_code'].value_counts().max(), 'occurrences')\n",
        "\n",
        "print('number of occurences per country are equal (between',\n",
        "      'Partner 1 and Partner 2):',\n",
        "      df_p1['p1.country_code'].value_counts().equals(\n",
        "          df_p2['p2.country_code'].value_counts()))\n",
        "\n",
        "print('number of occurences per country are equal [in Examples]:',\n",
        "      df_examples['p1.country_code'].value_counts().equals(\n",
        "          df_examples['p2.country_code'].value_counts()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sample points: 10000\n",
            "number of sample points [in Examples]: 499\n",
            "maximal occurnces per country: US with 962 occurrences\n",
            "number of occurences per country are equal (between Partner 1 and Partner 2): False\n",
            "number of occurences per country are equal [in Examples]: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KwtqG1ttXkg",
        "colab_type": "text"
      },
      "source": [
        "Let's examine missing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vozo0KRfPKE",
        "colab_type": "code",
        "outputId": "1410faa1-c3f6-4e06-d10d-8a056998b769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "print('\\nmissing data:')\n",
        "display(df_p1.isna().sum())\n",
        "display(df_p2.isna().sum())\n",
        "\n",
        "print('\\nmissing data in examples:')\n",
        "display(df_examples.isna().sum())\n",
        "\n",
        "display(df_p1.loc[df_p1['p1.country_code'].isna(), :].sort_values('p1.hotel_name'))\n",
        "display(df_p2.loc[df_p2['p2.country_code'].isna(), :].sort_values('p2.hotel_name'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "missing data:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "p1.key                 0\n",
              "p1.hotel_name          0\n",
              "p1.city_name           0\n",
              "p1.country_code        5\n",
              "p1.hotel_address       1\n",
              "p1.star_rating         0\n",
              "p1.postal_code      1750\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "p2.key                0\n",
              "p2.hotel_name         0\n",
              "p2.city_name          0\n",
              "p2.country_code       5\n",
              "p2.hotel_address      1\n",
              "p2.star_rating        0\n",
              "p2.postal_code      664\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "missing data in examples:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "p1.key               0\n",
              "p1.hotel_name        0\n",
              "p1.city_name         0\n",
              "p1.country_code      0\n",
              "p1.hotel_address     0\n",
              "p1.star_rating       0\n",
              "p1.postal_code      99\n",
              "p2.key               0\n",
              "p2.hotel_name        0\n",
              "p2.city_name         0\n",
              "p2.country_code      0\n",
              "p2.hotel_address     0\n",
              "p2.star_rating       0\n",
              "p2.postal_code      39\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p1.key</th>\n",
              "      <th>p1.hotel_name</th>\n",
              "      <th>p1.city_name</th>\n",
              "      <th>p1.country_code</th>\n",
              "      <th>p1.hotel_address</th>\n",
              "      <th>p1.star_rating</th>\n",
              "      <th>p1.postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9776</th>\n",
              "      <td>CBE71D01B60AF5E074935BCE2F434AF4</td>\n",
              "      <td>Bagatelle Kalahari Game Ranch Resort</td>\n",
              "      <td>Mariental</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Farm Bagatelle, D1268</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5735</th>\n",
              "      <td>C8A0A5B634A67365D57AB0983E601C62</td>\n",
              "      <td>Hotel Uhland</td>\n",
              "      <td>Windhoek</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147 Uhland Street</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4784</th>\n",
              "      <td>0AC418BC2D45A6B8518096F1F00AF00F</td>\n",
              "      <td>Kunene River Lodge</td>\n",
              "      <td>Kunene</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Banks of Kunene River 64km from Ruacana</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9896</th>\n",
              "      <td>F5782D38E38BE92661FC2A38A65335F1</td>\n",
              "      <td>Ndhovu Safari Lodge</td>\n",
              "      <td>Divundu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Okavango River, Entrance to Mahangu National Park</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6048</th>\n",
              "      <td>4B36DF6237887FEE1B7A51FFF8F5F79F</td>\n",
              "      <td>Protea Hotel Zambezi River</td>\n",
              "      <td>Katima Mullo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ngoma Road, Katima Mulilo</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                p1.key  ... p1.postal_code\n",
              "9776  CBE71D01B60AF5E074935BCE2F434AF4  ...           9000\n",
              "5735  C8A0A5B634A67365D57AB0983E601C62  ...           9000\n",
              "4784  0AC418BC2D45A6B8518096F1F00AF00F  ...           9000\n",
              "9896  F5782D38E38BE92661FC2A38A65335F1  ...           9000\n",
              "6048  4B36DF6237887FEE1B7A51FFF8F5F79F  ...            NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p2.key</th>\n",
              "      <th>p2.hotel_name</th>\n",
              "      <th>p2.city_name</th>\n",
              "      <th>p2.country_code</th>\n",
              "      <th>p2.hotel_address</th>\n",
              "      <th>p2.star_rating</th>\n",
              "      <th>p2.postal_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1303</th>\n",
              "      <td>5256D45F46338BFFA68B84A7BEC99146</td>\n",
              "      <td>Bagatelle Kalahari Game Ranch</td>\n",
              "      <td>Hardap</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bagatelle Kalahari Game Ranch D1268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5699</th>\n",
              "      <td>05E782BCA41AB39ED4F6602C9E54BAA8</td>\n",
              "      <td>Hotel Uhland</td>\n",
              "      <td>Windhoek</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147 Dr. Kenneth David Kaunda Street, former Uh...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7776</th>\n",
              "      <td>437A055FE6E759CCA7269E9F3AFAAA1B</td>\n",
              "      <td>Kunene River Lodge</td>\n",
              "      <td>Ehomba</td>\n",
              "      <td>NaN</td>\n",
              "      <td>D3701, Ruacana</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3134</th>\n",
              "      <td>9590C8BC8A30858FE272F3A08AD04173</td>\n",
              "      <td>Ndhovu Safari Lodge</td>\n",
              "      <td>Mahango</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C 48 Divundu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9672</th>\n",
              "      <td>AEA31679E9873B89508E6A95DF23BBD8</td>\n",
              "      <td>Protea Hotel by Marriott Zambezi River Lodge</td>\n",
              "      <td>Katima Mulilo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ngoma Road</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                p2.key  ... p2.postal_code\n",
              "1303  5256D45F46338BFFA68B84A7BEC99146  ...           9000\n",
              "5699  05E782BCA41AB39ED4F6602C9E54BAA8  ...           9000\n",
              "7776  437A055FE6E759CCA7269E9F3AFAAA1B  ...           9000\n",
              "3134  9590C8BC8A30858FE272F3A08AD04173  ...            NaN\n",
              "9672  AEA31679E9873B89508E6A95DF23BBD8  ...           9000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xRsc5XD2y1v",
        "colab_type": "text"
      },
      "source": [
        "We see some hotels have no country code. A bit problematic, but it's easy to see they are linked. We'll process them as an uknown country.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ZKVqFRffIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_p1.loc[df_p1['p1.country_code'].isna(), 'p1.country_code'] = 'UNK'\n",
        "df_p2.loc[df_p2['p2.country_code'].isna(), 'p2.country_code'] = 'UNK'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VshrTxeff6K",
        "colab_type": "text"
      },
      "source": [
        "Let's check the cities and star rating of the example, and how noisy they are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uslasies2Y4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "fdbe8e54-4f6b-4460-b96e-c584a4f047bc"
      },
      "source": [
        "def str_compare(row):\n",
        "  if len(row['p1.city_name']) > len(row['p2.city_name']):\n",
        "    res = ''.join(row['p1.city_name'].split(row['p2.city_name'])).strip()\n",
        "  elif len(row['p1.city_name']) < len(row['p2.city_name']):\n",
        "    res = ''.join(row['p2.city_name'].split(row['p1.city_name'])).strip()\n",
        "  else:\n",
        "    res = None\n",
        "\n",
        "  return res\n",
        "\n",
        "cities = df_examples.apply(str_compare, axis=1)\n",
        "print('Cities identical: {:.2%}'.format(cities.isna().sum()/len(cities)))\n",
        "print('Cities p1 and p2 differences (sample):\\n', cities.unique()[1:25])\n",
        "\n",
        "print('\\nHistogram of Star Rating Absolute Differences:')\n",
        "(df_examples['p1.star_rating'] - df_examples['p2.star_rating']).abs().hist();"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cities identical: 56.31%\n",
            "Cities p1 and p2 differences (sample):\n",
            " ['Mae Suai / Wiang Pa Pao (Chiang Rai)' 'Calangute' '(NY)' 'Onjuku'\n",
            " 'Shiretoko' 'Golden Triangle' 'Minamiizu' 'Lamai Beach' 'Taichung' '(TX)'\n",
            " 'Tonsai Beach' 'Shizuoka' 'Whitsunday Islands' 'La' 'Sunshine Coast'\n",
            " 'George Town' 'Yamanouchi' 'Thiruvananthapuram' '(MT)' '(NE)' 'City'\n",
            " 'Haiphong' 'Island' 'Seminyak']\n",
            "\n",
            "Histogram of Star Rating Absolute Differences:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBhnuktSg/wfknj0rg5BljAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzwR6kZJrS_3",
        "colab_type": "text"
      },
      "source": [
        "Some cities have an added \"(country_code)\" between p1 and p2, and some cities have a completely different name.\n",
        "Star ratings are also noisy, as seen in the historgram.\n",
        "Let's look at the postal codes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VvgCrUHrQEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7f39c035-38e2-4576-c65c-df6ea89437cf"
      },
      "source": [
        "print('P1 P2 data:')\n",
        "print('Percentage of postal codes that are integers: p1-{:.1%}, p2-{:.1%}'.\n",
        "        format(df_p1['p1.postal_code'].apply(\n",
        "            lambda x: type(x) in [int, float]).sum() / len(df_p1),\n",
        "            df_p2['p2.postal_code'].apply(\n",
        "            lambda x: type(x) in [int, float]).sum() / len(df_p2)))\n",
        "print('Percentage of postal codes that are strings: p1-{:.1%}, p2-{:.1%}'.\n",
        "        format(df_p1['p1.postal_code'].apply(\n",
        "            lambda x: type(x) == str).sum() / len(df_p1),\n",
        "            df_p2['p2.postal_code'].apply(\n",
        "            lambda x: type(x) == str).sum() / len(df_p2)))\n",
        "print('Percentage of postal codes that are NA: p1-{:.1%}, p2-{:.1%}'.\n",
        "        format(df_p1['p1.postal_code'].apply(\n",
        "            pd.isna).sum() / len(df_p1),\n",
        "            df_p2['p2.postal_code'].apply(\n",
        "            pd.isna).sum() / len(df_p2)))\n",
        "\n",
        "print('\\nExample data:')\n",
        "print('Percentage of postal codes that are integers: {:.1%}'.\n",
        "        format(df_examples['p1.postal_code'].apply(\n",
        "            lambda x: type(x) in [int, float]).sum() / len(df_examples)))\n",
        "print('Percentage of postal codes that are strings: {:.1%}'.\n",
        "        format(df_examples['p1.postal_code'].apply(\n",
        "            lambda x: type(x) == str).sum() / len(df_examples)))\n",
        "print('Percentage of postal codes that are NA: {:.1%}'.\n",
        "        format(df_examples['p1.postal_code'].apply(\n",
        "            pd.isna).sum() / len(df_examples)))\n",
        "print('Sample of postal codes: {}'.\n",
        "      format(df_examples['p1.postal_code'].unique()[:20]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P1 P2 data:\n",
            "Percentage of postal codes that are integers: p1-86.7%, p2-87.4%\n",
            "Percentage of postal codes that are strings: p1-13.3%, p2-12.6%\n",
            "Percentage of postal codes that are NA: p1-17.5%, p2-6.6%\n",
            "\n",
            "Example data:\n",
            "Percentage of postal codes that are integers: 87.8%\n",
            "Percentage of postal codes that are strings: 12.2%\n",
            "Percentage of postal codes that are NA: 19.8%\n",
            "Sample of postal codes: [nan 57170 403516 13441 '299-5107' 90100 '140-201' 560017 '099-4403'\n",
            " '135-915' 57150 528000 '415-0303' 630117 946 84310 40744 77840 50200\n",
            " 175131]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9j8QQGufxc",
        "colab_type": "text"
      },
      "source": [
        "The postal code statistics for the example data and p1/p2 are very similar, apart from the number of NAs in p2. It might indicate Examples data were drawn from the same distribution as the rest of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-_udR_b1V5c",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "Some helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJQ6owfPC8uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_pairs(df_base, pairs):\n",
        "  # calculate accuracy and coverage\n",
        "  \n",
        "  # df_base: pandas dataframe\n",
        "  # pairs: pandas dataframe\n",
        "\n",
        "  p1_col_ind = df_base.columns.get_loc('p1.key')\n",
        "  p2_col_ind = df_base.columns.get_loc('p2.key')\n",
        "\n",
        "  hits = 0\n",
        "  mismatch = pd.DataFrame(columns=pairs.columns)\n",
        "\n",
        "  for _, row in pairs.iterrows():\n",
        "    base_p1_ind = np.argwhere(df_base['p1.key'].str.findall(row['p1.key']))[0]\n",
        "    hits += df_base.iloc[base_p1_ind, p2_col_ind].values[0] == row['p2.key']\n",
        "\n",
        "    if df_base.iloc[base_p1_ind, p2_col_ind].values[0] != row['p2.key']:\n",
        "      mismatch = mismatch.append(row)\n",
        "\n",
        "  acc = hits / pairs.shape[0]\n",
        "  cov = hits / df_base.shape[0]\n",
        "  return acc, cov, mismatch\n",
        "\n",
        "\n",
        "def get_mismatches(df_base, pairs):\n",
        "  # get mismatches into one dataframe\n",
        "\n",
        "  # df_base: pandas dataframe\n",
        "  # pairs: pandas dataframe\n",
        "\n",
        "  # get relevant cols of p1 and p2\n",
        "  p1_col = [col for col in df_base if col.startswith('p1')]\n",
        "  p2_col = [col for col in df_base if col.startswith('p2')]\n",
        "\n",
        "  df_mismatch = pd.DataFrame(columns=p1_col+p2_col)\n",
        "\n",
        "  # join all pairs data into df_mismatch\n",
        "  for _, row in pairs.iterrows():\n",
        "    row_p1 = df_base.loc[df_base['p1.key'] == row['p1.key'], p1_col]\n",
        "    row_p2 = df_base.loc[df_base['p2.key'] == row['p2.key'], p2_col]\n",
        "    pair = pd.concat([row_p1.reset_index(drop=True), \n",
        "                      row_p2.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    df_mismatch = df_mismatch.append(pair, ignore_index=True)\n",
        "\n",
        "  return df_mismatch\n",
        "\n",
        "\n",
        "def get_match(df, pairs):\n",
        "  # return multiindex list-indices of pairs\n",
        "  links_arr = np.ndarray(shape=(2,0), dtype=int)\n",
        "  for _, row in pairs.iterrows():\n",
        "    if row['p1.key'] not in df['p1.key'].values:\n",
        "      continue\n",
        "    ind1 = df.loc[df['p1.key'] == row['p1.key'], :].index.values[0]\n",
        "    ind2 = df.loc[df['p2.key'] == row['p2.key'], :].index.values[0]\n",
        "    links_arr = np.hstack((links_arr, [[ind1], [ind2]]))\n",
        "  match_list = pd.MultiIndex.from_arrays(links_arr)\n",
        "  return match_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btmogsan7y7n",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "  Let's use the clean() method of recordlinkage which turns all strings into lowercase and\n",
        "  removes characters such as quotation marks and punctuation. Also,\n",
        "  it automatically removes leading and trailing white-space and\n",
        "  collapses consecutive white-space into a single space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJveQRkrkUOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(df):\n",
        "  if 'p1.country_code' in df.columns:\n",
        "    df.loc[df['p1.country_code'].isna(), 'p1.country_code'] = 'UNK'\n",
        "  if 'p2.country_code' in df.columns:\n",
        "    df.loc[df['p2.country_code'].isna(), 'p2.country_code'] = 'UNK'\n",
        "\n",
        "  key_cols = [col for col in df if col.endswith('key')]\n",
        "  country_code_cols = [col for col in df if col.endswith('country_code')]\n",
        "  star_rating_cols = [col for col in df if col.endswith('star_rating')]\n",
        "\n",
        "  for col in df.columns:\n",
        "    if col in key_cols + country_code_cols + star_rating_cols: continue\n",
        "    df.loc[:, col] = clean(df.loc[:, col])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGkKZqVp78dh",
        "colab_type": "text"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ovho4tpgt7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86f226c2-2835-46ee-8043-dda5062404c0"
      },
      "source": [
        "def star_rate_compare(s1, s2):\n",
        "  # if star_rate is at distance up to 0.5 then score is 1, else 0\n",
        "  concat = pd.concat([s1, s2], axis=1, ignore_index=True)\n",
        "\n",
        "  def star_comp(x):\n",
        "    dist = max(0, 1 - np.abs(x[1] - x[0]))\n",
        "    return float(dist)\n",
        "\n",
        "  return concat.apply(star_comp, axis=1)\n",
        "\n",
        "\n",
        "indexer = recordlinkage.Index()\n",
        "indexer.block(left_on='p1.country_code', right_on='p2.country_code')\n",
        "\n",
        "# set comparison parameters\n",
        "c = recordlinkage.Compare()\n",
        "c.string('p1.city_name', 'p2.city_name', label='city_name_lcs',\n",
        "         method='lcs')\n",
        "c.string('p1.city_name', 'p2.city_name', label='city_name_sw',\n",
        "        method='smith_waterman')\n",
        "c.string('p1.hotel_name', 'p2.hotel_name', label='hotel_name_lcs',\n",
        "         method='lcs')\n",
        "c.string('p1.hotel_name', 'p2.hotel_name', label='hotel_name_sw',\n",
        "        method='smith_waterman')\n",
        "c.string('p1.hotel_address', 'p2.hotel_address', label='hotel_address_sw',\n",
        "        method='smith_waterman')\n",
        "c.string('p1.hotel_address', 'p2.hotel_address', label='hotel_address_lcs',\n",
        "        method='lcs')\n",
        "c.string('p1.postal_code', 'p2.postal_code', label='postal_code_jarow',\n",
        "        method='jarowinkler')\n",
        "c.numeric('p1.star_rating', 'p2.star_rating', label='star_rating',\n",
        "          method='linear', origin=0, offset=0.5, scale=0.5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compare>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGn8WJD7bc__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48484a3b-6777-49be-df18-72f7730958c0"
      },
      "source": [
        "# prepare data\n",
        "X = df_examples.copy()\n",
        "\n",
        "# get true matches\n",
        "matches = X[['p1.key', 'p2.key']].copy()\n",
        "\n",
        "p1_cols = [col for col in X if col.startswith('p1')]\n",
        "p2_cols = [col for col in X if col.startswith('p2')]\n",
        "\n",
        "n_splits = 5\n",
        "kf = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "kf.get_n_splits(X)\n",
        "\n",
        "print(kf)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=5, random_state=0, shuffle=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP5DU8CtSqeV",
        "colab_type": "text"
      },
      "source": [
        "# Build models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqsbmbhATjOE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We'll use grid search for choosing model type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rNc-9lJTd95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PipeClassifier(SKLearnAdapter, BaseClassifier):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super().__init__()\n",
        "    \n",
        "    clf_pac = sklearn.linear_model.PassiveAggressiveClassifier()\n",
        "    clf_svm = sklearn.svm.NuSVC(probability=True, gamma='auto')\n",
        "    clf_rnf = ensemble.RandomForestClassifier()\n",
        "    clf_lrc = sklearn.linear_model.LogisticRegression()\n",
        "\n",
        "    param_grid = [\n",
        "    {\n",
        "    'clf': [clf_pac],\n",
        "    'clf__C': [0.5, 1],\n",
        "    },\n",
        "    {\n",
        "    'clf': [clf_lrc],\n",
        "    },\n",
        "    {\n",
        "    'clf': [clf_svm],\n",
        "    'clf__nu': [0.4, 0.5],\n",
        "    'clf__kernel': ['linear', 'rbf'],\n",
        "    },\n",
        "    {\n",
        "    'clf': [clf_rnf],\n",
        "    'clf__n_estimators': [6, 7, 8],\n",
        "    'clf__criterion': ['gini', 'entropy'],\n",
        "    'clf__min_samples_split': [4, 5],\n",
        "    }\n",
        "    ]\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('clf', clf_lrc),\n",
        "    ])\n",
        "\n",
        "    clf = model_selection.GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid,\n",
        "        cv=5,\n",
        "        n_jobs=-1)\n",
        "\n",
        "    # set the kernel\n",
        "    self.kernel = clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mcrPnEldGLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_pairs_to_links(prob_pairs):\n",
        "  df_prob = prob_pairs.reset_index()\n",
        "  df_prob = df_prob.rename({'level_0': 'p1', 'level_1': 'p2', 0: 'prob'}, axis=1)\n",
        "  df_prob = df_prob.sort_values('prob', ascending=False)\n",
        "\n",
        "  # print('lowest prob:', df_prob.iloc[df_prob['p1'].nunique() ,2])\n",
        "\n",
        "  pred_pairs = np.ndarray(shape=(2,0), dtype=int)  \n",
        "\n",
        "  for _, row in df_prob.iterrows():\n",
        "    p1_ind = int(row.values[0])\n",
        "    p2_ind = int(row.values[1])\n",
        "    if (p1_ind in pred_pairs[0, :]) or (p2_ind in pred_pairs[1, :]): continue\n",
        "    pred_pairs = np.hstack((pred_pairs, [[p1_ind], [p2_ind]]))\n",
        "\n",
        "  return pd.MultiIndex.from_arrays(pred_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZpoNmw7iC0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e580ec0d-d6c3-4b98-8e9a-f358fe94fbed"
      },
      "source": [
        "acc, cov = [], []\n",
        "\n",
        "# cross validate the models\n",
        "for count, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
        "  print('cv split', count, 'out of', n_splits)\n",
        "\n",
        "  # split train-test\n",
        "  X_train = X.iloc[train_index, :].copy()\n",
        "  X_test = X.iloc[test_index, :].copy()\n",
        "\n",
        "  # shuffle p2 rows\n",
        "  X_train = pd.concat([X_train[p1_cols],\n",
        "                       X_train[p2_cols].sample(\n",
        "                           frac=1, random_state=0).set_index(X_train.index)], \n",
        "                      axis=1)\n",
        "  X_test = pd.concat([X_test[p1_cols],\n",
        "                      X_test[p2_cols].sample(\n",
        "                          frac=1, random_state=0).set_index(X_test.index)],\n",
        "                     axis=1)\n",
        "\n",
        "  # train\n",
        "  # preprocess and indexer\n",
        "  X_train = preprocess(X_train)\n",
        "  candidate_links = indexer.index(X_train, X_train)\n",
        "  \n",
        "  # compute feature vectors\n",
        "  features = c.compute(candidate_links, X_train)\n",
        "\n",
        "  # get pair labels for features\n",
        "  true_pairs = get_match(X_train, matches)\n",
        "  true_pairs_ind = features.index & true_pairs\n",
        "\n",
        "  clf = PipeClassifier()\n",
        "  train_pred = clf.fit_predict(features, true_pairs_ind)\n",
        "  \n",
        "  # test\n",
        "  X_test = preprocess(X_test)\n",
        "  candidate_links = indexer.index(X_test, X_test)\n",
        "  features = c.compute(candidate_links, X_test)\n",
        "\n",
        "  # display(features.describe())\n",
        "\n",
        "  true_pairs = get_match(X_test, matches)\n",
        "  true_pairs_ind = features.index & true_pairs\n",
        "  prob_pairs = clf.prob(features)\n",
        "\n",
        "  pred_pairs = prob_pairs_to_links(prob_pairs)\n",
        "\n",
        "  # evaluate\n",
        "  # FP = true_pairs.difference(pred_pairs).size\n",
        "  # TP = true_pairs.intersection(pred_pairs).size\n",
        "  # print('Acc:', TP/pred_pairs.size)\n",
        "  # print('Cov:', TP/true_pairs.size)\n",
        "  \n",
        "  acc.append(recordlinkage.precision(true_pairs, pred_pairs))\n",
        "  cov.append(recordlinkage.recall(true_pairs, pred_pairs))\n",
        "\n",
        "print('Test accuracy: mean-{:.2%}, std-{:.2%}'.format(np.mean(acc), \n",
        "                                                      np.std(acc)))\n",
        "print('Test coverage: mean-{:.2%}, std-{:.2%}'.format(np.mean(cov),\n",
        "                                                      np.std(cov)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv split 1 out of 5\n",
            "cv split 2 out of 5\n",
            "cv split 3 out of 5\n",
            "cv split 4 out of 5\n",
            "cv split 5 out of 5\n",
            "Test accuracy: mean-100.00%, std-0.00%\n",
            "Test coverage: mean-100.00%, std-0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQPvKMoAYpWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3a70f6ab-d8e3-4833-c2e4-517c68d38cee"
      },
      "source": [
        "print(clf.kernel.best_estimator_)\n",
        "print(clf.kernel.best_params_)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory=None,\n",
            "         steps=[('clf',\n",
            "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
            "                                    fit_intercept=True, intercept_scaling=1,\n",
            "                                    l1_ratio=None, max_iter=100,\n",
            "                                    multi_class='auto', n_jobs=None,\n",
            "                                    penalty='l2', random_state=None,\n",
            "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                                    warm_start=False))],\n",
            "         verbose=False)\n",
            "{'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5OWzMpQYRYK",
        "colab_type": "text"
      },
      "source": [
        "# Untagged data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScBd9WdecGc0",
        "colab_type": "text"
      },
      "source": [
        "The blocks here are not indexed by country, due to long computational time.\n",
        "Instead, manually broken down by a for-loop for each country code.\n",
        "Also, iteratively picks up from the last country that was processed, that is for the case that the Colab connection breaks during the for-loop.\n",
        "Organize p1 and p2 keys and save to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD2qNQ37MKL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b52a748b-04bd-4550-dffd-366b2ab72c35"
      },
      "source": [
        "import os.path\n",
        "\n",
        "df_p1 = preprocess(df_p1)\n",
        "df_p2 = preprocess(df_p2)\n",
        "\n",
        "filepath = '/content/drive/My Drive/Work/Job Assignments/Agoda/ROI_MAISHAR/mappings.csv'\n",
        "\n",
        "# get last country that was processed\n",
        "if os.path.isfile(filepath):\n",
        "  with open(filepath, 'r', encoding='utf-8') as outfile:\n",
        "    pairs = pd.read_csv(outfile)\n",
        "    last_key = pairs.iloc[-1, 0]\n",
        "\n",
        "  last_country = df_p1.loc[df_p1['p1.key'] == last_key, 'p1.country_code'].values\n",
        "else:\n",
        "  last_country = ''\n",
        "\n",
        "# process by country_code blocks\n",
        "for country, df_p1_country in df_p1.groupby('p1.country_code'):\n",
        "  print(country)\n",
        "  if min(last_country, country) == country: continue\n",
        "\n",
        "  # prepare data\n",
        "  df_p2_country = df_p2.loc[df_p2['p2.country_code'] == country, :].set_index(df_p1_country.index)\n",
        "  X_test = pd.concat([df_p1_country, df_p2_country], axis=1).reset_index(drop=True)\n",
        "\n",
        "  # run prediction\n",
        "  candidate_links = indexer.index(X_test, X_test)\n",
        "  print(country, 'links:', candidate_links.shape[0])\n",
        "  features = c.compute(candidate_links, X_test)\n",
        "  prob_pairs = clf.prob(features)\n",
        "  pred_pairs = prob_pairs_to_links(prob_pairs)\n",
        "\n",
        "  # TODO: stay with multiindex instead of converting to ndarray\n",
        "  links_arr = np.ndarray(shape=(0,2), dtype=int)  \n",
        "  for link in pred_pairs:\n",
        "    links_arr = np.vstack((links_arr, link))\n",
        "\n",
        "  # join p1 and p2 keys\n",
        "  pairs = pd.concat(\n",
        "      [X_test.iloc[links_arr[:,0], X_test.columns.get_loc('p1.key')].reset_index(drop=True),\n",
        "      X_test.iloc[links_arr[:,1], X_test.columns.get_loc('p2.key')].reset_index(drop=True)],\n",
        "      axis=1, ignore_index=True)\n",
        "  pairs.rename(columns={0: \"P1.key\", 1: \"P2.key\"}, inplace=True)\n",
        "\n",
        "  with open(filepath, 'a+', encoding='utf-8') as outfile:\n",
        "    pairs.to_csv(outfile, index=False, header=False)\n",
        "\n",
        "print('done comp')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AE\n",
            "AL\n",
            "AR\n",
            "AT\n",
            "AU\n",
            "AZ\n",
            "BA\n",
            "BD\n",
            "BE\n",
            "BG\n",
            "BH\n",
            "BN\n",
            "BO\n",
            "BR\n",
            "BT\n",
            "BW\n",
            "CA\n",
            "CH\n",
            "CI\n",
            "CK\n",
            "CL\n",
            "CN\n",
            "CO\n",
            "CR\n",
            "CV\n",
            "CY\n",
            "CZ\n",
            "DE\n",
            "DK\n",
            "DO\n",
            "EE\n",
            "EG\n",
            "ES\n",
            "ET\n",
            "FI\n",
            "FJ\n",
            "FR\n",
            "GB\n",
            "GH\n",
            "GR\n",
            "GU\n",
            "HK\n",
            "HR\n",
            "HU\n",
            "ID\n",
            "IE\n",
            "IL\n",
            "IN\n",
            "IS\n",
            "IT\n",
            "JM\n",
            "JO\n",
            "JP\n",
            "KE\n",
            "KH\n",
            "KR\n",
            "KW\n",
            "KZ\n",
            "LA\n",
            "LB\n",
            "LK\n",
            "LT\n",
            "LU\n",
            "LV\n",
            "MA\n",
            "MD\n",
            "ME\n",
            "MG\n",
            "MK\n",
            "MM\n",
            "MN\n",
            "MO\n",
            "MP\n",
            "MT\n",
            "MU\n",
            "MV\n",
            "MX\n",
            "MY\n",
            "MZ\n",
            "NC\n",
            "NF\n",
            "NG\n",
            "NL\n",
            "NO\n",
            "NP\n",
            "NZ\n",
            "OM\n",
            "PA\n",
            "PE\n",
            "PF\n",
            "PG\n",
            "PH\n",
            "PK\n",
            "PL\n",
            "PR\n",
            "PT\n",
            "PW\n",
            "QA\n",
            "RE\n",
            "RO\n",
            "RS\n",
            "RU\n",
            "SA\n",
            "SC\n",
            "SE\n",
            "SG\n",
            "SI\n",
            "SK\n",
            "TH\n",
            "TN\n",
            "TO\n",
            "TR\n",
            "TW\n",
            "TZ\n",
            "UA\n",
            "UG\n",
            "UNK\n",
            "US\n",
            "UY\n",
            "VN\n",
            "VU\n",
            "WS\n",
            "XK\n",
            "ZA\n",
            "ZW\n",
            "done comp\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}